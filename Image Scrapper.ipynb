{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f59c87a-91c5-42b5-8aa4-95387f47b9ca",
   "metadata": {},
   "source": [
    "Q1. Write a python program to extract the video URL of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a61ea7ed-0135-4445-b72c-dd9cb44bc0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    # Find all elements containing video links\n",
    "    video_links = soup.find_all('a', {'id': 'video-title'})\n",
    "    \n",
    "    # Extract the URLs of the first five videos\n",
    "    for index, video_link in enumerate(video_links[:5]):\n",
    "        video_url = \"https://www.youtube.com\" + video_link['href']\n",
    "        print(f\"Video {index + 1} URL:\", video_url)\n",
    "else:\n",
    "    print(\"Failed to fetch the webpage.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e68fe6c-7b77-4143-ad78-f5de503c57fd",
   "metadata": {},
   "source": [
    "Q2. Write a python program to extract the URL of the video thumbnails of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ecad91f-ac2a-4b74-a2df-9e56274f2560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    # Find all elements containing video thumbnails\n",
    "    thumbnail_elements = soup.find_all('img', {'class': 'style-scope yt-img-shadow'})\n",
    "    \n",
    "    # Extract the URLs of video thumbnails for the first five videos\n",
    "    for index, thumbnail in enumerate(thumbnail_elements[:5]):\n",
    "        thumbnail_url = thumbnail['src']\n",
    "        print(f\"Thumbnail URL for Video {index + 1}:\", thumbnail_url)\n",
    "else:\n",
    "    print(\"Failed to fetch the webpage.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc1727a-179f-43d1-9de1-a5815ca62791",
   "metadata": {},
   "source": [
    "Q3. Write a python program to extract the title of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30bdde70-051a-42d2-b934-5c1e35de7ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    # Find all elements containing video titles\n",
    "    title_elements = soup.find_all('a', {'id': 'video-title'})\n",
    "    \n",
    "    # Extract the titles of the first five videos\n",
    "    for index, title in enumerate(title_elements[:5]):\n",
    "        video_title = title.text.strip()\n",
    "        print(f\"Title of Video {index + 1}: {video_title}\")\n",
    "else:\n",
    "    print(\"Failed to fetch the webpage.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1e3a02-7e87-49ea-bad1-48b47d3ade3c",
   "metadata": {},
   "source": [
    "Q4. Write a python program to extract the number of views of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3462e5ea-c847-41ed-8625-c51793b3d9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    # Find all elements containing video views\n",
    "    view_elements = soup.find_all('span', {'class': 'style-scope ytd-grid-video-renderer'})\n",
    "    \n",
    "    # Extract the number of views for the first five videos\n",
    "    view_count = []\n",
    "    for index, view in enumerate(view_elements[:5]):\n",
    "        view_text = view.get_text(strip=True)\n",
    "        if 'views' in view_text:  # Check if the element contains 'views' text\n",
    "            view_count.append(view_text)\n",
    "    \n",
    "    for idx, view in enumerate(view_count[:5]):\n",
    "        print(f\"Number of views for Video {idx + 1}: {view}\")\n",
    "else:\n",
    "    print(\"Failed to fetch the webpage.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fb29b5-c636-4142-93dc-7acd442f0f44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
